<!DOCTYPE html>
<html>
  <head>
    <title>Banana for scale</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { 
        font-family: 'Ubuntu Mono'; 
        font-size: 22px;
      }
      .remark-slide-content h1 { font-size: 75px; }
      .remark-slide-content { 
        font-size: 28px;
        padding: 1em 1em 1em 1em;
      }
      .title-slide {
        background-color: #272822;
        color: #f3f3f3;
        text-shadow: 0 0 20px #333;
      }
      .title-slide h1 {
        color: #f3f3f3;
        font-size: 150px;
      }
      .dark h1 {
        color: #202020;
        font-size: 150px;
      }
      .title-slide h2 {
        color: #f3f3f3;
        font-size: 100px;
      }
      .title-slide a {
        color: #f3f3f3;
        text-decoration:  none;
      }
       
    </style>
  </head>
  <body>
    <textarea id="source">



class: center, middle, title-slide
background-image: url(images/banana-scale.jpg)

---

class: center, middle, title-slide

# Banana for Scale

Some lessons learnt, 
and why bananas may not help.

[Albert de Jongh](https://www.linkedin.com/in/albertdejongh) and [Chris Oloff](http://twitter.com/chrisoloff)

---

# Disclaimer

## Please Note

All names, examples, figures and PITAs presented and discussed during this talk
are anecdotal. Any resemblance of or similarity to real people, systems or
companies would be accidental.

Sorry to disappoint.

???
Before we start, audience must understand that even though our experience is
based on real life projects / situations, all examples presented are
fictituous.

---

# Scope

- Scaling / Scalability?

???
Scaling can mean many things / involve many disciplines: Team structure /
growth, organisational setup, which hardware to choose

--
- Keeping a transactional system with massive growth afloat operationally

???
We'll cover just a small fraction of all this (actually based on our
experience), coming into a situation that has some pressure and unhappiness
already.

--
- Technical aspects of scaling

???
And as we are software engineers / architects, we'll cover technical aspects,
mainly. But, as may become clear, the greatest technology might be useless if
applied in the wrong place... thus it's never about technology only.

---

# Some kind of outline

1. Know your metrics
2. Know your system
3. Change one thing at a time

???
We will talk about 3 items only, but in some detail. These are our main
lessons, or principles, we want to bring across.

If you remember nothing else but those in 2 months from now, then that would be
awesome, and we would have done a good job.

- We want you to understand that metrics, meaning actually measuring your system
is important. We feel the metrics we will present are somehow generic, and may
be applicable in your case as well. But this might be wrong. So please don't
copy our metrics blindly, but rather try to understand why we chose the ones we
chose; remember the principles involved rather than the actual implementation.

- We've learnt the next lesson the hard way: Chances are that you made
technology choices *before* having to scale that do the job perfectly well, are
a lovely abstraction, making it unnecessary for you to worry about the
intrinsic details of (example) distributed transactions... but when your
transaction volume hits a certain limit, stuff starts to break, and you realise
that you know nothing about its internal mechanics. The early blessings of the
big framework turn into its curse... and the sales reps that made you purchase
that middleware to exactly avoid scaling problems initially... they cannot find
you a single technical expert that knows more than you do already. Thus, you
really should know your system.

- The third items is a simple principle: If you change one thing at a time
only, it's easy to attribute the effects to a cause, namely the single thing
you changed. Unfortunately, we tend to break this simple rule. If, as a result
of listening to our story, only one of you resists the temptation to change
multiple things at a time... then we've achieved something.

---

layout: false
class: title-slide, center, middle
background-image: url(images/know-your-metrics.jpg)

# Know your Metrics

???

> A banana added for scale or used as a system of measurement is so much easier
and less snobby than inches, feet or even the metric system.

Imgur user HowToBeADad on http://imgur.com/gallery/Jrmlt

---

# Why Metrics?

--

What Matters Actually?

--

Happiness? Happy customers? Happy stakeholders?

???
What's the link between happy stakeholders and metrics?

The link is: complex systems

Complex systems (like transaction processing systems) are complex... and have
many stakeholders.

Complex systems struggle under load, or even break.

If the system breaks or is slow, everybody will be unhappy
(except for maybe competitors).

--

Don't break!

--

Don't make me wait!

???
Many things influence happiness of our stakeholders, but from an operational /
scaling / growth perspective, having to wait (or timeout with an error) is
BAAAAD.

---

# Is anybody waiting?

--

How do we know?

--

Metrics?

???
Interaction: What metrics? Who in the audience has metrics? (Probably the majority won't have any / won't know)
Yes, there are always metrics of sorts...

--

Logs?

???
Let's check log files

Let's check a log file of a transaction processing system.

(app, master branch 20 req per second)
(look at logs)

Apperently we can buy bananas here via an HTTP POST.

And there are metrics! For each request we see how long it took.

Are we done? Is anybody waiting?

Closer look: Many response times look good, below 200ms.

First idea: Determine the average response time, then we can compare if
response time is getting better or worse.

(switch branch to measure-averages)

We can now get the average:

curl -s http://localhost:3080/averageMetrics | json

The average is okay, but the maxResponseTime indicates that at least one
request was served poorly. Or many? How many?

---

# Don't be Just Average

Since the last restart of the server 97267 seconds ago, we received
1166409 requests, and in the average a request took 863ms.

???
Problem: the average becomes meaningless over time: If something started going
wrong (and users started screaming) 2 minutes ago, the average response time
won't indicate anything bad, until poor performance affects the average (of
maybe a very long time).

Conclusion: We need recency! What was the response time *in the last
minute(s)*?

But there is another issue, consider this example:

--

We need *recency*.

--

Average response time is 185ms. Sounds acceptable!

--

... Out of 1000 requests, 980 of them took 25ms, and 20 took 8000ms.

???
The average is: (980 * 25 + 20 * 8000) / 1000 ... better than 200ms in the average.

20 requests are an issue! And just with an average, we won't see that.

Solution: percentiles

--

We need *percentiles*.

---

class: center, middle

background-image: url(images/percentile-80.gif)

???

What are percentiles? Think of 100 people and their body height, make them
stand next to each other, sorted by height. The height of the 80th from the
left marks the 80th percentile: 80% of people have equal or less hight to that guy.

Transferred to response times: If the 99th percentile is 900ms, then 99 percent
of requests are responded with in 900ms or less. (And the remaining 1% in 900ms
or more.)

(recency etc, as per presentation)

---

# Recency and Percentiles

- reservoir sampling
- forward decaying priority sampling

???
This gets complicated quite quickly.

--

... we don't want to implement that ourselves

--

... rather use libraries smart people have created. Thanks, Coda Hale!

[Metrics Library](https://github.com/dropwizard/metrics) (For Java, many ports available)

--

Highly recommended: [Metrics, Metrics Everywhere](https://www.youtube.com/watch?v=czes-oa0yik)

???
Metrics, Metrics Everywhere: It's about linking code with business value (and
explaining important aspects of metrics in detail)

Let's look at that.

(app, metrics branch)

curl -s http://localhost:3001/metrics | json

---

# Metrics?

What have we got now?

- Recency
- Percentiles

So what?

--

- Now we can compare

???

Side Note (TODO: where?)
Tools that aggregate data from log files might help, there are even open source
one's that do that, e.g. "logstash" and http://www.elasticsearch.org/overview/kibana/ ... good idea to use!

But... does it help with metrics? Let's see... we can most likely get the
*average response time* via such a tool.

(the fictituous server can maybe show the average response time on a uri?)

---

layout: false
class: center, middle
background-image: url(images/Windflower-05237-nevit.JPG)

???
We don't have the same load all the time. There's a 24 hour cycle (people
transact most in the morning and in the afternoon), and there are weekly,
monthly and yearly cycles, too.

---

layout: false
class: center, middle
background-image: url(images/graph-1.jpg)

???
This graph shows the request rate over time, in #requests per second, in an
online transaction processing system.

... so what?

Record request rates (TPS) and response times (percentiles) over time

... make meaningful observations. Example: response times (95th percentile)
degraded from 700ms to 1200mm, while the request rate was the same as
previously. Now we can conclude: It's not simply higher demand that causes decay.

... we can also compare days and weeks (assuming that we record those metrics
appropriately). We'll see why this is so important later.

---

layout: false
class: center, middle, title-slide

## Know your Metrics &#10003;

---

layout: false
class: title-slide, center, middle

background-image: url(images/dials.jpg)
# Know your System

???
Chris and myself have way too often received phone calls about big systems that are very slow or unstable - usually late on a Saturday just as my steak is ready...

If you're in a rush to fix things you're often tempted to start tuning away all those problems.

---

## Where do you start?

* HTTP connection queue
--

* HTTP thread pools
--

* OS TCP/IP stack 
--

* Camel thread pools
--

* JDBC connection pools
--

* MDB pool size
--

* Bean caches
--

* Hibernate caches
--

* HTTP client pool size
--

* Message broker
--

* Database magic
--

* Heap sizes
--

* Garbage collection algorithm
--

* JVM flags

---

class: title-slide, center, middle

background-image: url(images/plane.jpg)

???
This part of our talk is about how important it is for you to really understand your system before you are tempted to start fiddling with all the shiny knobs to make it go faster.

Let's go through some examples of things that went horribly wrong, and see if we can learn something from them...

This is really a therapy session for us to work through some of the things we cannot unsee

** Next slide intro **

We were trying to get everyone to correctly setup their monitoring software.

Some well-meaning soul thought setting the Glassfish transaction monitoring to LOW will help.  
And it does - mostly - how else can we get data for our metrics?

---

## Glassfish monitoring

```java
"p: thread-pool-1; w: 179" daemon prio=3 tid=0x00000000014c7000 nid=0x58b1 
waiting for monitor entry [0xfffffd7dff2f0000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.util.Vector.addElement(Vector.java:572)
        - waiting to lock <0xfffffd7e20b52080> (a java.util.Vector)
        at com.sun.enterprise.distributedtx.J2EETransactionManagerImpl
             .begin(J2EETransactionManagerImpl.java:959)
        ...
```

???

**Raise your hand if you think this looks dodgy**

Almost all threads that had anything to do with transactions were blocked

---

## Glassfish monitoring

One thread had the lock and was scanning through a vector:

```java
"p: thread-pool-1; w: 174" daemon prio=3 tid=0x000000000ae81800 nid=0x58ab 
runnable [0xfffffd7dff9f8000]
   java.lang.Thread.State: RUNNABLE
        at java.util.Vector.indexOf(Vector.java:361)
*        - locked <0xfffffd7e20b52080> (a java.util.Vector)
        at java.util.Vector.indexOf(Vector.java:335)
        at java.util.Vector.removeElement(Vector.java:594)
*        - locked <0xfffffd7e20b52080> (a java.util.Vector)
        at java.util.Vector.remove(Vector.java:745)
        at com.sun.enterprise.distributedtx.J2EETransactionManagerImpl
             .monitorTxCompleted(J2EETransactionManagerImpl.java:1384)
        ...
```

???
And one thread had the vector and was scanning through it

Transaction monitoring was synchronizing on one counter to count transactions

** Lessons **
* What exactly does LOW mean?
* Complexity comes at a price
* At high speeds wind resistance counts!

---

class: title-slide, middle, center

## tx.commit, please?
## computer says no

???
Client complained about database constraint violations in the logs, and they were getting more and more frequent.

It was quite strange since the system was using Hibernate for persistence

Hibernate was using sequences to create the ids

Therefore it should not possible for the ids to clash.

---

## Integers

Integer maximum value 2^31-1 = 2147483647

???
Let's delve into this a little bit

The maximum value of 32 bit signed integer is...

--

Increment by 1 gives you -2147483648

???
In Java, if you increment an integer beyond its maximum value it will wrap to the negative value, and give you..

--

At 10 TPS:  59652 hours (6.8 years)

???
At 10 TPS you will burn through the positive IDs in just less than 7 years

--

At 200 TPS:  2982 hours (124 days)

???
At 200 TPS you will destroy them in 124 days

**Pause**

Can you guess what happened here?

Third party component was using integers for its id field

Single sequence used across different tables

Therefore "holes" in the range of ids in the different tables  

Using an integer for an id is dangerous

--

Rather use a long, with max of 9223372036854775807

???
Rather use a long, with max of 
nine quintillion two hundred twenty-three quadrillion three hundred seventy-two trillion thirty-six billion eight hundred fifty-four million seven hundred seventy-five thousand eight hundred seven

--

At 200 TPS that will last... 1462356043 years

???

**Lessons**
* Your system will grow much faster than you anticipate
* Do not just blindly trust third-party libraries!

---

class: title-slide, center, middle

background-image: url(images/garbage-bins.jpg)

???
This is a favourite of mine - good old garbage collection in Java

**How many of you have tuned garbage collection in Java?**

**How many of you actually made it better?**

**How do you know if was better?**

GC is especially hard to tune correctly if you have app with high memory churn

---

## Garbage collection

If your heap is too small - frequent collections, but all the time

???
Very frequent full collections of the stop-the-world type

--

So you fix it by having a HUGE heap

And it runs a **monster** stop the world collection

Everything stops

And people die

???

Fix it by having a HUGE heap

Now you are deferring the obvious...  and now you have a huge stop-the-world pause

--

Swap to disk

???
Even worse - if you're oversubscribing memory in the system it may start swapping to disk during GC

Then it becomes really really slow

--

Collector implementation and parameters

???
Change one thing at a time, and study the results

** Lessons **
* Understand your application's memory usage patterns.  You may even have to change it.
* Experiment where no one can get hurt (do try this at home)
* Have verbose gc logs switched on (with some other switches) - and analyze it

---
class: title-slide, center, middle

background-image: url(images/chicken-virtualization.jpg)

???
What can we learn from this picture?

It is very hard to find a picture on virtualization :-)

---

## Virtualization

```bash
23:02:50 up 8 days, 11:01,  6 users,  load average: 1.01, 1.00, 0.81
```

???

This is an example of a load average metric from a Linux system

Explain what it tells you

You have know how many CPUs the system has - explain

--

What does it mean when the CPU is virtual?

???
Virtual CPU

--

Or, if the CPU allocation is dynamically scaled?

???
Dynamically scaled?

*** Lessons ***
* Very short and sweet - It is hard to understand how your system is doing if you don't understand the tech it is running on
* You have to really really understand your virtualization technology

---

class: title-slide

background-image: url(images/cromemco.jpg)

???
Back to a real life example

The system mysteriously started slowing down more and more

All the normal culprits were investigated - could not really find the cause

Eventually some thread dumps were produced

---

## Glassfish transaction journal

```java
"p: thread-pool-1; w: 273" daemon prio=3 tid=0x000000000cc35000 nid=0x7e3c1 
waiting for monitor entry [0xfffffd7fdbd73000]
  java.lang.Thread.State: BLOCKED (on object monitor)
  at com.sun.jts.CosTransactions.LogFile.write(LogFile.java:157)
*  waiting to lock <0xfffffd7e810a6ff8> (a com.sun.jts.CosTransactions.LogFile)
  at com.sun.jts.CosTransactions.CoordinatorLog.formatLogRecords(CoordinatorLog.java:1082)
  locked <0xfffffd7e7b645ef8> (a com.sun.jts.CosTransactions.CoordinatorLog)
  at com.sun.jts.CosTransactions.CoordinatorLog.write(CoordinatorLog.java:535)
  at com.sun.jts.CosTransactions.TransactionState.setState(TransactionState.java:780)
  at com.sun.jts.CosTransactions.TopCoordinator.commit(TopCoordinator.java:2134)
```

???
So what went wrong here?

**Pause**

Glassfish writes a transaction log to be able to complete transactions on a crash
		
This log was on a file system where application logs were been written
		
Since they were trying to solve a problem log levels were set high and lots of logs
		
Slowing down the transaction log

** Lessons **
* Systems can share resources in surprising ways

---

class: title-slide, center, bottom

background-image: url(images/file-handles.jpg)

## (file handles, btw)

???
This time the call was more serious

The system just stopped working

---

## File handles

```java
*java.io.FileNotFoundException: .../imq/instances/imqbroker/etc/passwd 
  (Too many open files)
  at java.io.FileInputStream.open(Native Method)
  at java.io.FileInputStream.<init>(FileInputStream.java:106)
  ...
```

???

Log fragment in the message broker log file

** Pause **

Listed all the open files to see which process was holding on to the handles

It was the Java virtual machine "local attach" mechanism - as in when using tools like jconsole and jvisualvm

It was leaking file handles

We were embarrased to find that it was our JMX metrics collector running on the broker that triggered a bug in the JVM

** Lessons **
* Soak test all parts of your application - even the monitoring bits

---

class: title-slide, center, middle

background-image: url(images/queue.jpg)


???

This is a quirky problem we had with message queues

**What exactly does the queue length tell you?**

Both messages that still need to be consumed AND messages that have been picked up but not committed

Recently had this very strange problem where messages would look as if they are stuck on a queue, but not all the consumers would be busy

Had us flummoxed for a while - until we realized that you can set up a prefetch message count

This is the number of messages that will be predelivered to a consumer in a batch for performance

In this case the few busy consumers had prefetched all the messages off the queue - and the other consumers were idle

However the first message in the prefetched list was poisonous, and the consumer dealt with it badly

It held up all the messages in the prefetched list - and they were stuck forever

A bit like standing in the queue at Pick 'n Pay and the person right at the front has an item without a price

** Lessons **
* Not sure...  universe is out to get us?

---

class: title-slide, center, middle

background-image: url(images/Box-cutter.jpg)

???

Cheap tools at clients

---

## Cheap tools

Thread dumps - the poor man's production profiler

--

Print the garbage collection stats

--

Be proactive - look at the system when it is busy

--

Replaying?

--

Centralized view of everything (logs, errors, metrics)

---

layout: false
class: center, middle, title-slide

## Know your System &#10003;

---

layout: false
class: title-side, middle, center, dark
background-image: url(images/ford-consul-cortina-electrical-system-wiring-diagram.jpg)

# Change One Thing at a Time

???
As last item on the agenda, something more relaxing.

It sounds so simple... why is it worth mentioning?

Let's look at an (again purely fictituous) example.

---

layout: true

# The simple rule we broke

---

> "The bean pool is at its limit under load, let's double it. It will certainly
reduce response times in the average."

--

> "We can certainly reduce garbage collection waits by adding 50% more GC
threads. As there's enough CPU, there is no risk here!"

--

We make the changes together (no time to lose!)

Just one maintenance window a day!

---

Response times degrade even more  :(

--

All we can do is an emergency rollback...

And we are as smart (or dumb) as before

???
The tragic is: We want to make progress, be helpful, and we are pretty damn
sure that the two changes are low risk and unrelated.

Also: Often we cannot make changes any time in production, we have to wait for
a maintenance window, adhere to a strict process, thus "batching up" production
changes seems useful!

---

layout: false

class: title-slide, center, bottom

background-image: url(images/correlation.png)

### http://xkcd.com/552/

???

Cause and Effect are often not what we expect.

Assumptions is the mother of all ____ups.

---


# Some kind of outline

1. Know your metrics
2. Know your system
3. Change one thing at a time

---

class: center, middle, title-slide
# Questions?

    </textarea>
    <!-- online URL is http://gnab.github.io/remark/downloads/remark-latest.min.js -->
    <script src="remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({
        //ratio: '16:9',
        slideNumberFormat: '' 
    } );
    </script>
  </body>
</html>
